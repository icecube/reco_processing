{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simweights\n",
    "import pickle\n",
    "import os, sys\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib as mat\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import tables\n",
    "import h5py\n",
    "import math\n",
    "from scipy.stats import mstats\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as font_manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/data/user/tvaneede/GlobalFit/reco_processing/notebooks/weighting\")\n",
    "from weights import *\n",
    "from utils import *\n",
    "from selections import selection_mask\n",
    "from fonts import *\n",
    "from plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the custom module path\n",
    "sys.path.append(\"/data/user/tvaneede/GlobalFit/reco_processing\")\n",
    "\n",
    "# Import the datasets module\n",
    "from datasets import datasets\n",
    "\n",
    "# set the inputs\n",
    "reco_versions = [\"evtgen_v1_rec_v2\", \"spice_tau_reco\"]\n",
    "\n",
    "# Dynamically select the desired dataset\n",
    "simulation_datasets = {}\n",
    "for reco_version in reco_versions: simulation_datasets[reco_version] = getattr(datasets, reco_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "livetime_yr = 11.687\n",
    "livetime_s  = livetime_yr * 365.25 * 24 * 3600 # 11.687 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_plotting_path = f\"/data/user/tvaneede/GlobalFit/reco_processing/notebooks/compare_spice_ftp/output\"\n",
    "os.system(f\"mkdir -p {main_plotting_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_datasets( simulation_dataset, keys_to_merge ):\n",
    "\n",
    "    # open the files\n",
    "    for key in simulation_dataset:\n",
    "        print(f\"----- Extracting files for {key}\")\n",
    "        simulation_dataset[key]['hdf_file'] = pd.HDFStore(simulation_dataset[key]['hdf_file_path'],'r')\n",
    "        simulation_dataset[key]['weighter'] = simweights.NuGenWeighter( simulation_dataset[key]['hdf_file'] ,nfiles=simulation_dataset[key]['nfiles'])\n",
    "\n",
    "    # merging files\n",
    "    for new_key in keys_to_merge:\n",
    "        print(f\"----- Creating new key {new_key}\")\n",
    "        simulation_dataset[new_key] = {}\n",
    "        simulation_dataset[new_key]['variables'] = {}\n",
    "        simulation_dataset[new_key]['weighter'] = None\n",
    "\n",
    "        for key in keys_to_merge[new_key]:\n",
    "            \n",
    "            print(f\"Using {key}\")\n",
    "            # merge the weighters\n",
    "            if simulation_dataset[new_key]['weighter'] == None:\n",
    "                simulation_dataset[new_key]['weighter'] = simulation_dataset[key]['weighter']\n",
    "            else: simulation_dataset[new_key]['weighter'] += simulation_dataset[key]['weighter']\n",
    "\n",
    "    return simulation_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_merge = {}\n",
    "\n",
    "keys_to_merge[\"evtgen_v1_rec_v2\"] = {\n",
    "    \"NuE\" : [\"NuE_midE\", \"NuE_highE\"],\n",
    "    \"NuMu\" : [\"NuMu_midE\", \"NuMu_highE\"],\n",
    "    \"NuTau\" : [\"NuTau_midE\", \"NuTau_highE\"],\n",
    "    \"NuAll\" : ['NuE', \"NuMu\", \"NuTau\"],\n",
    "}\n",
    "\n",
    "keys_to_merge[\"spice_tau_reco\"] = {\n",
    "    \"NuE\" : [\"NuE_midE1\", \"NuE_highE1\", \"NuE_midE2\", \"NuE_highE2\"],\n",
    "    \"NuMu\" : [\"NuMu_midE1\", \"NuMu_highE1\",\"NuMu_midE2\", \"NuMu_highE2\"],\n",
    "    \"NuTau\" : [\"NuTau_midE1\", \"NuTau_highE1\",\"NuTau_midE2\", \"NuTau_highE2\"],\n",
    "    \"NuAll\" : ['NuE', \"NuMu\", \"NuTau\"],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Extracting files for NuTau_midE\n",
      "----- Extracting files for NuTau_highE\n",
      "----- Extracting files for NuE_midE\n",
      "----- Extracting files for NuE_highE\n",
      "----- Extracting files for NuMu_midE\n",
      "----- Extracting files for NuMu_highE\n",
      "----- Creating new key NuE\n",
      "Using NuE_midE\n",
      "Using NuE_highE\n",
      "----- Creating new key NuMu\n",
      "Using NuMu_midE\n",
      "Using NuMu_highE\n",
      "----- Creating new key NuTau\n",
      "Using NuTau_midE\n",
      "Using NuTau_highE\n",
      "----- Creating new key NuAll\n",
      "Using NuE\n",
      "Using NuMu\n",
      "Using NuTau\n",
      "----- Extracting files for NuTau_midE1\n",
      "----- Extracting files for NuTau_highE1\n",
      "----- Extracting files for NuTau_midE2\n",
      "----- Extracting files for NuTau_highE2\n",
      "----- Extracting files for NuE_midE1\n",
      "----- Extracting files for NuE_highE1\n",
      "----- Extracting files for NuE_midE2\n",
      "----- Extracting files for NuE_highE2\n",
      "----- Extracting files for NuMu_midE1\n",
      "----- Extracting files for NuMu_highE1\n",
      "----- Extracting files for NuMu_midE2\n",
      "----- Extracting files for NuMu_highE2\n",
      "----- Creating new key NuE\n",
      "Using NuE_midE1\n",
      "Using NuE_highE1\n",
      "Using NuE_midE2\n",
      "Using NuE_highE2\n",
      "----- Creating new key NuMu\n",
      "Using NuMu_midE1\n",
      "Using NuMu_highE1\n",
      "Using NuMu_midE2\n",
      "Using NuMu_highE2\n",
      "----- Creating new key NuTau\n",
      "Using NuTau_midE1\n",
      "Using NuTau_highE1\n",
      "Using NuTau_midE2\n",
      "Using NuTau_highE2\n",
      "----- Creating new key NuAll\n",
      "Using NuE\n",
      "Using NuMu\n",
      "Using NuTau\n"
     ]
    }
   ],
   "source": [
    "for key in simulation_datasets: simulation_datasets[key] = open_datasets( simulation_datasets[key], keys_to_merge[key] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight functions\n",
    "spline_file = '/data/ana/Diffuse/NNMFit/MCEq_splines/v1.2.1/MCEq_splines_PRI-Gaisser-H4a_INT-SIBYLL23c_allfluxes.pickle'\n",
    "\n",
    "# conventional            \n",
    "flux_keys_conv =  ['conv_antinumu','conv_numu','conv_antinue','conv_nue','conv_antinutau','conv_nutau']\n",
    "spline_object_conv = SplineHandler(spline_file, flux_keys_conv)\n",
    "conv_flux = spline_object_conv.return_weight\n",
    "generator_conv = lambda pdgid, energy, cos_zen: conv_flux(pdgid, energy, cos_zen)\n",
    "\n",
    "# prompt\n",
    "flux_keys_pr =  ['pr_antinumu','pr_numu','pr_antinue','pr_nue','pr_antinutau','pr_nutau']\n",
    "spline_object_pr = SplineHandler(spline_file, flux_keys_pr)\n",
    "pr_flux = spline_object_pr.return_weight\n",
    "generator_pr = lambda pdgid, energy, cos_zen: pr_flux(pdgid, energy, cos_zen)\n",
    "\n",
    "# astro\n",
    "gamma_astro = 2.87\n",
    "per_flavor_norm = 2.12\n",
    "def AstroFluxModel(pdgid, energy, cos_zen):\n",
    "    flux = 0.5*(per_flavor_norm*1e-18)*(energy/1e5)**-gamma_astro\n",
    "    return flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     astro_NuE    astro_NuMu   astro_NuTau            conv        prompt\n",
      "evtgen_v1_rec_v2  56.20 ± 0.54  14.74 ± 0.22  33.91 ± 0.39  32.356 ± 0.968  12.47 ± 0.10\n",
      "spice_tau_reco    56.77 ± 0.56  20.42 ± 0.22  34.89 ± 0.43  38.766 ± 0.947  13.41 ± 0.11\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for key in simulation_datasets:\n",
    "\n",
    "    simulation_dataset = simulation_datasets[key]\n",
    "\n",
    "    channel_data = {}\n",
    "\n",
    "    for flavor in ['NuE', \"NuMu\", \"NuTau\"]:\n",
    "        weights = simulation_dataset[flavor][\"weighter\"].get_weights(AstroFluxModel) * livetime_s\n",
    "        rate = np.sum(weights)\n",
    "        error = np.sqrt(np.sum(weights**2))\n",
    "        channel_data[f\"astro_{flavor}\"] = f\"{rate:.2f} ± {error:.2f}\"\n",
    "\n",
    "    # Conventional\n",
    "    flavor = \"NuAll\"\n",
    "    weights_conv = simulation_dataset[flavor][\"weighter\"].get_weights(generator_conv) * livetime_s\n",
    "    rate_conv = np.sum(weights_conv)\n",
    "    err_conv = np.sqrt(np.sum(weights_conv**2))\n",
    "    channel_data[\"conv\"] = f\"{rate_conv:.3f} ± {err_conv:.3f}\"\n",
    "\n",
    "    # Prompt\n",
    "    weights_prompt = simulation_dataset[flavor][\"weighter\"].get_weights(generator_pr) * livetime_s\n",
    "    rate_prompt = np.sum(weights_prompt)\n",
    "    err_prompt = np.sqrt(np.sum(weights_prompt**2))\n",
    "    channel_data[\"prompt\"] = f\"{rate_prompt:.2f} ± {err_prompt:.2f}\"\n",
    "\n",
    "    data[key] = channel_data\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "\n",
    "# Optional: specify column order\n",
    "columns_order = [f\"astro_{flavor}\" for flavor in ['NuE', 'NuMu', 'NuTau']] + [\"conv\", \"prompt\"]\n",
    "df = df[columns_order]\n",
    "\n",
    "# Display as string table\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why am I getting 0 weights for the conventional flux? I only printed the numbers from nutau. Now fixed!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-v4.4.1_reco-v1.1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
